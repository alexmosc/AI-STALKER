{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db36a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Load NN\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_tokenizer_and_model(model_name_or_path):\n",
    "  return GPT2Tokenizer.from_pretrained(model_name_or_path), \\\n",
    "    GPT2LMHeadModel.from_pretrained(model_name_or_path).to(DEVICE)\n",
    "\n",
    "# Load model from local dir\n",
    "\n",
    "tokenizer, model = load_tokenizer_and_model(\"models/aistalker/final/\")\n",
    "\n",
    "model.eval() #freeze gradient calc\n",
    "\n",
    "print('Model was loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3c4e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences function was defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Define sentences function\n",
    "\n",
    "def split_into_sentences(text):\n",
    "\n",
    "        alphabets = \"([А-Яа-я])\"\n",
    "        prefixes = \"(Гн|Др|Ув|Тов)[.]\"\n",
    "        suffixes = \"(Inc|Ltd|Jr|Sr|Co|тыс|млн|руб)\"\n",
    "        starters = \"(Гн|Др|Ув|Тов|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "        acronyms = \"([А-Я][.][А-Я][.](?:[А-Я][.])?)\"\n",
    "        websites = \"[.](com|net|org|io|gov|ru|ch|su|ai|ua|kz|by)\"\n",
    "        digits = \"([0-9])\"\n",
    "        \n",
    "        text = ' <br>'.join(text.splitlines())\n",
    "        \n",
    "        text = text.replace(\"\\...\", \"\\.\")\n",
    "        \n",
    "        text = re.sub(digits + \"[.]\" + digits, \"\\\\1<prd>\\\\2\", text)\n",
    "        text = re.sub(\"([А-Яа-я])\" + \"[.]\" + digits, \"\\\\1<prd>\\\\2\", text)\n",
    "        text = re.sub(\"([A-Za-z])\" + \"[.]\" + digits, \"\\\\1<prd>\\\\2\", text)\n",
    "        text = re.sub(\"([А-Яа-я])\" + \"[.]\" + \"([А-Яа-я])\", \"\\\\1<prd>\\\\2\", text)\n",
    "        text = re.sub(\"([A-Za-z])\" + \"[.]\" + \"([A-Za-z])\", \"\\\\1<prd>\\\\2\", text)\n",
    "        text = re.sub(\"([а-я])\" + \"[.]\" + \"[ ]\" + \"([а-я])\", \"\\\\1<prd>\\\\2\", text)\n",
    "        text = \" \" + text + \"  \"\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        text = text.replace(\"<p>\", \"\")\n",
    "        text = re.sub(prefixes, \"\\\\1<prd>\", text)\n",
    "        text = re.sub(websites, \"<prd>\\\\1\", text)\n",
    "        if \"Ph.D\" in text: text = text.replace(\"Ph.D.\", \"Ph<prd>D<prd>\")\n",
    "        text = re.sub(\"\\s\" + alphabets + \"[.] \", \" \\\\1<prd> \", text)\n",
    "        text = re.sub(acronyms + \" \" + starters, \"\\\\1<stop> \\\\2\", text)\n",
    "        text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\", \"\\\\1<prd>\\\\2<prd>\\\\3<prd>\", text)\n",
    "        text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\", \"\\\\1<prd>\\\\2<prd>\", text)\n",
    "        text = re.sub(\" \" + suffixes + \"[.] \" + starters, \" \\\\1<stop> \\\\2\", text)\n",
    "        text = re.sub(\" \" + suffixes + \"[.]\", \" \\\\1<prd>\", text)\n",
    "        text = re.sub(\" \" + alphabets + \"[.]\", \" \\\\1<prd>\", text)\n",
    "        if \"”\" in text: text = text.replace(\".”\", \"”.\")\n",
    "        if \"\\\"\" in text: text = text.replace(\".\\\"\", \"\\\".\")\n",
    "        if \"!\" in text: text = text.replace(\"!\\\"\", \"\\\"!\")\n",
    "        if \"?\" in text: text = text.replace(\"?\\\"\", \"\\\"?\")\n",
    "        text = text.replace(\"<prd>\", \".\")\n",
    "        text = text.replace(\".\", \".<stop>\")\n",
    "        text = text.replace(\"?\", \"?<stop>\")\n",
    "        text = text.replace(\"!\", \"!<stop>\")\n",
    "\n",
    "        sentences = text.split(\"<stop>\")\n",
    "        sentences = sentences[:-1]\n",
    "        sentences = [s.strip() for s in sentences]\n",
    "\n",
    "        return sentences\n",
    "\n",
    "print('Sentences function was defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ccd3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative functions were defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Define Generate functions\n",
    "\n",
    "import re\n",
    "\n",
    "def generate_story_start(\n",
    "    model, \n",
    "    tok, \n",
    "    text,\n",
    "    max_length = 350,\n",
    "    top_k = 5,\n",
    "    top_p = 0.95,\n",
    "    temperature = 1.2,\n",
    "    do_sample = True,\n",
    "    num_beams = 3,\n",
    "    no_repeat_ngram_size = 3,\n",
    "    repetition_penalty = 2.,\n",
    "    num_sentences = 4\n",
    "    ):\n",
    "\n",
    "    input_ids = tok.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    out = model.generate(\n",
    "      input_ids,\n",
    "      max_length=max_length,\n",
    "      repetition_penalty=repetition_penalty,\n",
    "      do_sample=do_sample,\n",
    "      top_k=top_k, top_p=top_p, temperature=temperature,\n",
    "      num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size\n",
    "      )\n",
    "\n",
    "    generated_content = list(map(tok.decode, out))[0]\n",
    "    \n",
    "    #input_ids_len = len(tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE).tolist()[0])\n",
    "    \n",
    "    last_text = '''— Твой путь начинается '''\n",
    "    \n",
    "    story_sentences = split_into_sentences(generated_content.split(last_text)[-1])#[0:num_sentences]\n",
    "    story_sentences = story_sentences[:-1]\n",
    "    \n",
    "    #print(generated_content)\n",
    "    #print(story_sentences)\n",
    "    \n",
    "    story_sentences = [sent for sent in story_sentences if \"div\" not in sent]\n",
    "    story_sentences = [sent for sent in story_sentences if \"def\" not in sent]\n",
    "    story_sentences = [sent for sent in story_sentences if \"php\" not in sent]\n",
    "    story_sentences = [sent for sent in story_sentences if \"http\" not in sent]\n",
    "    story_sentences = [sent for sent in story_sentences if \"css\" not in sent]\n",
    "    story_sentences = [sent for sent in story_sentences if \"Глава\" not in sent]\n",
    "\n",
    "    story_start = 'Твой путь начинается ' + ' '.join(story_sentences)\n",
    "    \n",
    "    story_start = re.sub('\\s+', ' ', story_start)\n",
    "    story_start = re.sub(\"[\\<\\[].*?[\\>\\]]\", \"\", story_start)\n",
    "    story_start = re.sub(\"[\\{\\[].*?[\\}\\]]\", \"\", story_start)\n",
    "    story_start = re.sub(\"\\*\", \"\", story_start)\n",
    "\n",
    "    return story_start\n",
    "\n",
    "def generate_story_actions(\n",
    "    model, \n",
    "    tok, \n",
    "    text,\n",
    "    max_length = 500,\n",
    "    top_k = 5,\n",
    "    top_p = 0.95,\n",
    "    do_sample = True,\n",
    "    temperature = 1.2,\n",
    "    num_beams = 3,\n",
    "    no_repeat_ngram_size = 3,\n",
    "    repetition_penalty = 2.,\n",
    "    last_text = None,\n",
    "    num_sentences = 3\n",
    "    ):\n",
    "\n",
    "    input_ids = tok.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    out = model.generate(\n",
    "      input_ids,\n",
    "      max_length=max_length,\n",
    "      repetition_penalty=repetition_penalty,\n",
    "      do_sample=do_sample,\n",
    "      top_k=top_k, top_p=top_p, temperature=temperature,\n",
    "      num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size\n",
    "      )\n",
    "\n",
    "    generated_content = list(map(tok.decode, out))[0]\n",
    "    \n",
    "    #input_ids_len = len(tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE).tolist())\n",
    "    #print(input_ids_len)\n",
    "    \n",
    "    story_sentences = split_into_sentences(generated_content.split(last_text)[-1])#[0:num_sentences]\n",
    "    story_sentences = story_sentences[:-1]\n",
    "    \n",
    "    #print(generated_content)\n",
    "    #print(story_sentences)\n",
    "    \n",
    "    story_sentences = [sent for sent in story_sentences if \"div\" not in sent]\n",
    "    story_sentences = [sent for sent in story_sentences if \"def\" not in sent]\n",
    "    story_sentences = [sent for sent in story_sentences if \"php\" not in sent]\n",
    "    story_sentences = [sent for sent in story_sentences if \"http\" not in sent]\n",
    "    story_sentences = [sent for sent in story_sentences if \"css\" not in sent]\n",
    "    story_sentences = [sent for sent in story_sentences if \"Глава\" not in sent]\n",
    "\n",
    "    story_action = ' '.join(story_sentences)\n",
    "    \n",
    "    story_action = re.sub('\\s+', ' ', story_action)\n",
    "    story_action = re.sub(\"[\\<\\[].*?[\\>\\]]\", \"\", story_action)\n",
    "    story_action = re.sub(\"[\\{\\[].*?[\\}\\]]\", \"\", story_action)\n",
    "    story_action = re.sub(\"\\*\", \"\", story_action)\n",
    "    \n",
    "    story_action = re.sub('\\s+', ' ', story_action)\n",
    "    story_action = re.sub(\"[\\<\\[].*?[\\>\\]]\", \"\", story_action)\n",
    "    story_action = re.sub(\"[\\{\\[].*?[\\}\\]]\", \"\", story_action)\n",
    "    story_action = re.sub(\"\\*\", \"\", story_action)\n",
    "\n",
    "    return story_action\n",
    "\n",
    "print('Generative functions were defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9183ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History function was defined\n"
     ]
    }
   ],
   "source": [
    "# Update history function\n",
    "\n",
    "def update_message_history(df, message_details, df_name):\n",
    "\n",
    "    # Update message history\n",
    "\n",
    "    df.loc[len(df)] = message_details\n",
    "\n",
    "    df.to_csv('./ai_stalker_bot_messages/' + df_name, index = False)\n",
    "\n",
    "    return df\n",
    "\n",
    "print('History function was defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c214fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Prompts for few shot inferences\n",
    "\n",
    "story_start_promt = '''— Твой путь начинается в баре \"100 рентген\", куда ты пришел пополнить арсенал оружия, сдать пару артефактов, выпить пива и послушать сталкеров.\n",
    "\n",
    "— Твой путь начинается у НИИ \"Агропром\", где, судя по слухам, есть подземные сооружения и даже, возможно, остатки военной лаборатории.\n",
    "\n",
    "— Твой путь начинается в Болотах. Вокруг, куда ни глянь, рыжеватая растительность и бочаги с водой. На горизонте виднеется крыша чьего-то домика.\n",
    "\n",
    "— Твой путь начинается около Дикой территории, куда ты собрался пробраться завтра с рассветом, а сегодня нашел овраг под деревом в чахлом лесу и затаился на ночь.\n",
    "\n",
    "— Твой путь начинается промозглой ночью, когда сквозь облака едва проглядывала бледно-жёлтая луна, ты поднял лежащий на коленях АКМ и пошел на свет аномалии.\n",
    "\n",
    "— Твой путь начинается '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7cfb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './ai_stalker_bot_messages/ai_stalker_bot_logs_152936290.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025C05FC7448>, 'Connection to api.telegram.org timed out. (connect timeout=20)'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025C0BC92C08>, 'Connection to api.telegram.org timed out. (connect timeout=20)'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025C0BC92A48>, 'Connection to api.telegram.org timed out. (connect timeout=20)'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025BC4A3A088>, 'Connection to api.telegram.org timed out. (connect timeout=20)'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025C0BC80E48>, 'Connection to api.telegram.org timed out. (connect timeout=20)'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025C05FD3C08>, 'Connection to api.telegram.org timed out. (connect timeout=20)'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025BC4A34588>, 'Connection to api.telegram.org timed out. (connect timeout=20)'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C05FC7808>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCA7A48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC9A4C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC92B48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC85B08>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCACA08>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C05FC7948>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCA78C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCAA848>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC9DA48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCAC788>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC82488>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC85C48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025B923D8C08>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC9A6C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C05FD3A08>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C05FCBE08>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC9A648>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCAC348>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC80308>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC80A48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCAC608>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C05FC7448>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC98088>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC98BC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC9AAC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCAC308>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCDD608>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCAC8C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC98308>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCE9308>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCE1E48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCDDDC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C05FC70C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCEDFC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCACEC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C05FD3B08>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCF9CC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCF9E48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCE1D88>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC9AFC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BD059C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BC98F88>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C05FD3F88>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BD0F6C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCA7A48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BD070C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCF3DC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BD193C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C05FC7AC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCAC788>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BD240C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE/getUpdates?offset=699267677&timeout=20 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025C0BCAAC08>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './ai_stalker_bot_messages/ai_stalker_bot_logs_124074525.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "2022-09-21 21:22:15,969 (__init__.py:986 MainThread) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message text is empty\"\n",
      "2022-09-21 21:22:15,970 (__init__.py:988 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 977, in __threaded_polling\n",
      "    self.worker_pool.raise_exceptions()\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 154, in raise_exceptions\n",
      "    raise self.exception_info\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 98, in run\n",
      "    task(*args, **kwargs)\n",
      "  File \"C:\\Users\\burna\\AppData\\Local\\Temp\\ipykernel_3464\\3955236341.py\", line 208, in handle_text\n",
      "    bot.send_message(message.chat.id, story_action)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 1454, in send_message\n",
      "    entities, allow_sending_without_reply, protect_content=protect_content))\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 276, in send_message\n",
      "    return _make_request(token, method_url, params=payload, method='post')\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 161, in _make_request\n",
      "    json_result = _check_result(method_name, result)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 188, in _check_result\n",
      "    raise ApiTelegramException(method_name, result, result_json)\n",
      "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message text is empty\n",
      "\"\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n",
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "2022-09-27 10:57:05,050 (__init__.py:986 MainThread) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 403. Description: Forbidden: bot was blocked by the user\"\n",
      "2022-09-27 10:57:05,051 (__init__.py:988 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 977, in __threaded_polling\n",
      "    self.worker_pool.raise_exceptions()\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 154, in raise_exceptions\n",
      "    raise self.exception_info\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 98, in run\n",
      "    task(*args, **kwargs)\n",
      "  File \"C:\\Users\\burna\\AppData\\Local\\Temp\\ipykernel_3464\\3955236341.py\", line 208, in handle_text\n",
      "    bot.send_message(message.chat.id, story_action)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 1454, in send_message\n",
      "    entities, allow_sending_without_reply, protect_content=protect_content))\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 276, in send_message\n",
      "    return _make_request(token, method_url, params=payload, method='post')\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 161, in _make_request\n",
      "    json_result = _check_result(method_name, result)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 188, in _check_result\n",
      "    raise ApiTelegramException(method_name, result, result_json)\n",
      "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 403. Description: Forbidden: bot was blocked by the user\n",
      "\"\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "2022-09-27 11:14:00,582 (__init__.py:986 MainThread) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 403. Description: Forbidden: bot was blocked by the user\"\n",
      "2022-09-27 11:14:00,584 (__init__.py:988 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 977, in __threaded_polling\n",
      "    self.worker_pool.raise_exceptions()\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 154, in raise_exceptions\n",
      "    raise self.exception_info\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 98, in run\n",
      "    task(*args, **kwargs)\n",
      "  File \"C:\\Users\\burna\\AppData\\Local\\Temp\\ipykernel_3464\\3955236341.py\", line 208, in handle_text\n",
      "    bot.send_message(message.chat.id, story_action)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 1454, in send_message\n",
      "    entities, allow_sending_without_reply, protect_content=protect_content))\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 276, in send_message\n",
      "    return _make_request(token, method_url, params=payload, method='post')\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 161, in _make_request\n",
      "    json_result = _check_result(method_name, result)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 188, in _check_result\n",
      "    raise ApiTelegramException(method_name, result, result_json)\n",
      "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 403. Description: Forbidden: bot was blocked by the user\n",
      "\"\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "2022-09-27 11:14:07,120 (__init__.py:986 MainThread) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 403. Description: Forbidden: bot was blocked by the user\"\n",
      "2022-09-27 11:14:07,121 (__init__.py:988 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 977, in __threaded_polling\n",
      "    self.worker_pool.raise_exceptions()\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 154, in raise_exceptions\n",
      "    raise self.exception_info\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 98, in run\n",
      "    task(*args, **kwargs)\n",
      "  File \"C:\\Users\\burna\\AppData\\Local\\Temp\\ipykernel_3464\\3955236341.py\", line 208, in handle_text\n",
      "    bot.send_message(message.chat.id, story_action)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 1454, in send_message\n",
      "    entities, allow_sending_without_reply, protect_content=protect_content))\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 276, in send_message\n",
      "    return _make_request(token, method_url, params=payload, method='post')\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 161, in _make_request\n",
      "    json_result = _check_result(method_name, result)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 188, in _check_result\n",
      "    raise ApiTelegramException(method_name, result, result_json)\n",
      "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 403. Description: Forbidden: bot was blocked by the user\n",
      "\"\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "2022-09-27 18:30:23,583 (__init__.py:986 MainThread) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 403. Description: Forbidden: bot was blocked by the user\"\n",
      "2022-09-27 18:30:23,584 (__init__.py:988 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 977, in __threaded_polling\n",
      "    self.worker_pool.raise_exceptions()\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 154, in raise_exceptions\n",
      "    raise self.exception_info\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 98, in run\n",
      "    task(*args, **kwargs)\n",
      "  File \"C:\\Users\\burna\\AppData\\Local\\Temp\\ipykernel_3464\\3955236341.py\", line 208, in handle_text\n",
      "    bot.send_message(message.chat.id, story_action)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 1454, in send_message\n",
      "    entities, allow_sending_without_reply, protect_content=protect_content))\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 276, in send_message\n",
      "    return _make_request(token, method_url, params=payload, method='post')\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 161, in _make_request\n",
      "    json_result = _check_result(method_name, result)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 188, in _check_result\n",
      "    raise ApiTelegramException(method_name, result, result_json)\n",
      "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 403. Description: Forbidden: bot was blocked by the user\n",
      "\"\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "2022-09-28 02:24:24,722 (__init__.py:986 MainThread) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 502. Description: Bad Gateway\"\n",
      "2022-09-28 02:24:24,723 (__init__.py:988 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 976, in __threaded_polling\n",
      "    polling_thread.raise_exceptions()\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 116, in raise_exceptions\n",
      "    raise self.exception_info\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 98, in run\n",
      "    task(*args, **kwargs)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 603, in __retrieve_updates\n",
      "    timeout=timeout, long_polling_timeout=long_polling_timeout)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 575, in get_updates\n",
      "    json_updates = apihelper.get_updates(self.token, offset, limit, timeout, allowed_updates, long_polling_timeout)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 333, in get_updates\n",
      "    return _make_request(token, method_url, params=payload)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 161, in _make_request\n",
      "    json_result = _check_result(method_name, result)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 188, in _check_result\n",
      "    raise ApiTelegramException(method_name, result, result_json)\n",
      "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 502. Description: Bad Gateway\n",
      "\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n",
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n",
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 01:43:08,181 (__init__.py:986 MainThread) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 502. Description: Bad Gateway\"\n",
      "2022-10-08 01:43:08,182 (__init__.py:988 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 976, in __threaded_polling\n",
      "    polling_thread.raise_exceptions()\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 116, in raise_exceptions\n",
      "    raise self.exception_info\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\util.py\", line 98, in run\n",
      "    task(*args, **kwargs)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 603, in __retrieve_updates\n",
      "    timeout=timeout, long_polling_timeout=long_polling_timeout)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\__init__.py\", line 575, in get_updates\n",
      "    json_updates = apihelper.get_updates(self.token, offset, limit, timeout, allowed_updates, long_polling_timeout)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 333, in get_updates\n",
      "    return _make_request(token, method_url, params=payload)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 161, in _make_request\n",
      "    json_result = _check_result(method_name, result)\n",
      "  File \"C:\\Users\\burna\\anaconda3\\envs\\aistalker\\lib\\site-packages\\telebot\\apihelper.py\", line 188, in _check_result\n",
      "    raise ApiTelegramException(method_name, result, result_json)\n",
      "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 502. Description: Bad Gateway\n",
      "\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n",
      "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Run bot\n",
    "\n",
    "import telebot\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Создаем экземпляр бота\n",
    "\n",
    "bot = telebot.TeleBot(\"5519125691:AAE_BzeKOviflo-bY3QmXkck6TLns88_LgE\")\n",
    "\n",
    "# Функция, обрабатывающая команду /start\n",
    "\n",
    "@bot.message_handler(commands=[\"start\"])\n",
    "def start(message, res=False):\n",
    "    \n",
    "    # Text to the user\n",
    "    \n",
    "    manual = '''*******\n",
    "    \n",
    "    Советы для новых игроков:\n",
    "    \n",
    "    Писать лучше полными предложениями: Я пошел..., Я сказал: ..., ..., - обратился я к нему, Я направил ...\n",
    "\n",
    "    Если предложение на оканчивается знаком препинания то модель допишет его за вас, как ей вздумается. Например, \"Я вижу на горизонте лес, на его опушке\", а модель довершит описание сцены.\n",
    "    \n",
    "    Если в своем представлении вы указали конкретные локации, персонажей, лут и т.д. будьте готовы, что система будет их часто упоминать.\n",
    "    Хорошая идея - описать локации, монстров, предметы и т.п., которые хотите видеть в игре, и они точно будут.\n",
    "    \n",
    "    Бывает, что клиент подвисает и тогда нет фразы \"Пишу историю...\", через 10 секунд надо повторить ввод.\n",
    "    \n",
    "    Удачной охоты!\n",
    "    \n",
    "    *******\n",
    "    '''\n",
    "    \n",
    "    bot.send_message(message.chat.id, manual)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    bot.send_message(message.chat.id, 'Опусти оружие, путник, и ответь, кто ты и зачем здесь.')\n",
    "    \n",
    "    # Get user id and create the unique message history for them\n",
    "    \n",
    "    message_user_id = str(message.from_user.id)\n",
    "    \n",
    "    # Create a local file with message logs for unique user, for each new game (after pressing /start)\n",
    "\n",
    "    ai_stalker_bot_logs = pd.DataFrame(\n",
    "        columns = ['chat_id', 'user_id', 'message_id', 'is_bot', 'message_datetime', 'message_text']\n",
    "        )\n",
    "    \n",
    "    ai_stalker_bot_logs.to_csv('./ai_stalker_bot_messages/ai_stalker_bot_logs' + '_' + str(message_user_id) + '.csv'\n",
    "                               , index = False\n",
    "                              )\n",
    "\n",
    "# Получение сообщений от юзера\n",
    "\n",
    "@bot.message_handler(content_types=[\"text\"])\n",
    "def handle_text(message):\n",
    "    \n",
    "    # Make sure to cut input\n",
    "    \n",
    "    message_text = message.text\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        input_ids = tokenizer.encode(message_text, return_tensors=\"pt\").to(DEVICE)\n",
    "        \n",
    "        good_message = True\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        good_message = False\n",
    "    \n",
    "    if not good_message:\n",
    "        \n",
    "        bot.send_message(message.chat.id, 'Что ты прошептал? Уши забило фиолетовым мхом, плохо слышу.')\n",
    "        \n",
    "    else:\n",
    "\n",
    "        # Get user id and use the unique message history for them\n",
    "        \n",
    "        message_user_id = str(message.from_user.id)\n",
    "\n",
    "        df_name = 'ai_stalker_bot_logs_' + message_user_id + '.csv'\n",
    "\n",
    "        ai_stalker_bot_logs = pd.read_csv('./ai_stalker_bot_messages/' + df_name)\n",
    "\n",
    "        # Check if the story has just started (zero row dataframe)\n",
    "\n",
    "        len_ai_stalker_bot_logs = len(ai_stalker_bot_logs)\n",
    "\n",
    "        if len_ai_stalker_bot_logs == 0:\n",
    "\n",
    "            ## dataframe of length 0\n",
    "\n",
    "            message_chat_id = str(message.chat.id)\n",
    "            message_user_id = message_user_id\n",
    "            message_message_id = str(message.message_id)\n",
    "            message_is_bot = message.from_user.is_bot\n",
    "            message_message_datetime = str(message.date)\n",
    "            message_message_text = message_text[:500]\n",
    "\n",
    "            # Update message history\n",
    "\n",
    "            ai_stalker_bot_logs = update_message_history(\n",
    "                ai_stalker_bot_logs\n",
    "                , [\n",
    "                    message_chat_id,\n",
    "                    message_user_id,\n",
    "                    message_message_id,\n",
    "                    message_is_bot,\n",
    "                    message_message_datetime,\n",
    "                    message_message_text\n",
    "                ]\n",
    "                , df_name\n",
    "            )\n",
    "\n",
    "            # Text\n",
    "\n",
    "            bot.send_message(message.chat.id, 'Жую жгучий пух и забиваю трубку из кости псевдо-филина, да ты не шелести особо.')\n",
    "\n",
    "            # Create story start with NN (use story promts)\n",
    "\n",
    "            story_start = generate_story_start(model, tokenizer, story_start_promt)\n",
    "\n",
    "            bot.send_message(message.chat.id, story_start)\n",
    "\n",
    "            time.sleep(7)\n",
    "\n",
    "            bot.send_message(message.chat.id, 'Что думаешь делать дальше?')\n",
    "\n",
    "            # Update message history\n",
    "\n",
    "            ai_stalker_bot_logs = update_message_history(\n",
    "                        ai_stalker_bot_logs\n",
    "                        , [\n",
    "                        str(message.chat.id),\n",
    "                        str(777),\n",
    "                        str(0),\n",
    "                        True,\n",
    "                        str(int(time.time())),\n",
    "                        story_start[:400]\n",
    "                        ]\n",
    "                , df_name\n",
    "                )\n",
    "\n",
    "        else: \n",
    "\n",
    "            ## dataframe of length 2 and more\n",
    "\n",
    "            # record player's reply\n",
    "\n",
    "            message_chat_id = str(message.chat.id)\n",
    "            message_user_id = message_user_id\n",
    "            message_message_id = str(message.message_id)\n",
    "            message_is_bot = message.from_user.is_bot\n",
    "            message_message_datetime = str(message.date)\n",
    "            message_message_text = message_text[:250]\n",
    "\n",
    "            # Update message history\n",
    "\n",
    "            ai_stalker_bot_logs = update_message_history(\n",
    "                    ai_stalker_bot_logs\n",
    "                    , [\n",
    "                    message_chat_id,\n",
    "                    message_user_id,\n",
    "                    message_message_id,\n",
    "                    message_is_bot,\n",
    "                    message_message_datetime,\n",
    "                    message_message_text\n",
    "                ]\n",
    "                , df_name\n",
    "            )\n",
    "\n",
    "            ## Generate infeence on the reply\n",
    "\n",
    "            player_action_promt = ''\n",
    "\n",
    "            len_ai_stalker_bot_logs = len(ai_stalker_bot_logs)\n",
    "\n",
    "            if len_ai_stalker_bot_logs <= 9:\n",
    "\n",
    "                for index, row in ai_stalker_bot_logs.iterrows():\n",
    "                    if index <= 1:\n",
    "                        player_action_promt += row['message_text'] + '\\n\\n'\n",
    "                    else:\n",
    "                        player_action_promt += row['message_text'] + ' '\n",
    "\n",
    "            else:\n",
    "\n",
    "                for index, row in ai_stalker_bot_logs.iterrows():\n",
    "                    if index <= 1:\n",
    "                        player_action_promt += row['message_text'] + '\\n\\n'\n",
    "                    elif index >= len(ai_stalker_bot_logs) - 7:\n",
    "                        player_action_promt += row['message_text'] + ' '\n",
    "\n",
    "            #print(player_action_promt)\n",
    "\n",
    "            # Text\n",
    "\n",
    "            bot.send_message(message.chat.id, 'Пишу историю...')\n",
    "            \n",
    "            last_text = player_action_promt[-20:]\n",
    "\n",
    "            story_action = generate_story_actions(model, tokenizer, text = player_action_promt, last_text = last_text)\n",
    "\n",
    "            bot.send_message(message.chat.id, story_action)\n",
    "\n",
    "            # Update message history\n",
    "\n",
    "            ai_stalker_bot_logs = update_message_history(\n",
    "                        ai_stalker_bot_logs\n",
    "                        , [\n",
    "                        str(message.chat.id),\n",
    "                        str(777),\n",
    "                        str(0),\n",
    "                        str(True),\n",
    "                        str(int(time.time())),\n",
    "                        story_action[-250:]\n",
    "                        ]\n",
    "                , df_name\n",
    "                )\n",
    "\n",
    "\n",
    "### Starting bot\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            bot.polling(none_stop = True, interval = 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            \n",
    "            print(e)\n",
    "\n",
    "            time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52ba83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
